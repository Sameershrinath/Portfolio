<section class="project-essay">
    <h2>Retrieval-Augmented Generation (RAG) Pipeline for Document Querying</h2>
    
    <center><iframe width="640" height="360" src="https://www.youtube.com/embed/wLr9g4WILdw"
        title="Upload Any PDF &amp; Chat: Build Your Own RAG Chatbot with Local LLM | how to make a local LLM Chatbot ?"
        frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </center>
    
    <h3>Overview</h3>
    <p>
        Developed a Retrieval-Augmented Generation (RAG) pipeline that enables users to query and interact with
        documents in natural language. The system processes PDF files by chunking them, generating embeddings, and
        storing these embeddings in an OpenSearch Vector Database for high-precision semantic retrieval.
    </p>
    <h3>Tech Stack</h3>
    <div style="display: flex; justify-content: center; gap: 16px; margin: 16px 0;">
        <span
            style="background-color:#3572A5; color:white; padding:8px 20px; border-radius:20px; font-size:15px; font-weight:500;">
            Python
        </span>
        <span
            style="background-color:#FFD43B; color:#222; padding:8px 20px; border-radius:20px; font-size:15px; font-weight:500;">
            Embeddings
        </span>
        <span
            style="background-color:#0C4B33; color:white; padding:8px 20px; border-radius:20px; font-size:15px; font-weight:500;">
            Ollama + Gemma3:1B LLM
        </span>
        <span
            style="background-color:#2196F3; color:white; padding:8px 20px; border-radius:20px; font-size:15px; font-weight:500;">
            OpenSearch VectorDB
        </span>
    </div>
    <h3>Key Features</h3>
    <ul>
        <li>Provides contextual and accurate answers by grounding responses in documents.</li>
        <li>Handles large unstructured datasets efficiently with vector similarity search.</li>
        <li>Improves information retrieval speed and user experience compared to traditional search/chatbots.</li>
        <li>Scalable and adaptable for use cases like research, customer support, and knowledge management.</li>
    </ul>
    <h3>Integration</h3>
    <p>
        Integrated Ollama with Gemma3:1B LLM to deliver context-aware, document-grounded responses, improving accuracy
        and relevance in real-time interactions.
    </p>
</section>